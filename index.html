<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Sebastian Dittert</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<style>
			.maintenance-message {
				text-align: center;
				padding: 100px 20px;
				color: #666;
			}
			.maintenance-message h2 {
				color: #333;
				margin-bottom: 20px;
				font-size: 2em;
			}
			.maintenance-message p {
				font-size: 1.2em;
				line-height: 1.6;
				max-width: 600px;
				margin: 0 auto;
			}
			.maintenance-icon {
				font-size: 4em;
				color: #4acaa8;
				margin-bottom: 30px;
			}
		</style>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/avatar.jpg" alt="" /></a>
					<h1><strong>Sebastian Dittert</strong> <br/>
					M.Sc. in Mechanical Engineering <br />
					Reinforcement Learning | Robotics <br />
		
					</h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- Maintenance Message -->
				<section id="maintenance">
					<div class="maintenance-message">
						<div class="maintenance-icon">ðŸ”§</div>
						<h2>Website Under Maintenance</h2>
						<p>I'm currently updating my website with new content and improvements. Please check back soon for the latest information about my work in reinforcement learning and robotics.</p>
						<p>In the meantime, feel free to connect with me through the links in the sidebar.</p>
					</div>
				</section>

				<!-- Commented out sections for future restoration -->
				<!-- 
				<section id="one">
					<header class="major">
						<h2>About myself</h2>
					</header>
					<p> Starting from my studies as a mechanical engineer, I developed a strong interest in artificial intelligence, more precisely machine learning. I am particularly interested in the topic of Deep Reinforcement Learning. Besides theoretical topics of reinforcement learning like new algorithms or problems like artificial curiosity, I am also interested in the application of robotic and autonomous systems like self-driving cars. Therefore i taught myself programming parallel to my studies and completed several online courses like: 
						<ul>
							<li>Artificial Intelligence Nanodegree at Udacity (2020)</li>
							<li>Deep Reinforcement Learning Nanodegree at Udacity (2019)</li>
							<li>Self-Driving Car Engineer Nanodegree at Udacity (2018) </li>
						</ul>	
						I was also able to do an internship for my master's degree as a machine learning engineer at ABB. Here I mainly worked on a project for automated stacking and reclaiming of an open cast mine by using reinforcement learning. Subsequently, I managed to write my master's thesis at ZF with the topic: <i>"Optimization of the adaptive control of a damper system/chassis system through fast-learning deep reinforcement learning algorithms"</i>. 
					</p>
					<ul class="actions">
						<li><a href="CV/Sebastian_Dittert_CV_new.pdf" class="button">CV</a></li>
					</ul>
				</section>

				<section id="two">
					<h2>Recent Work</h2>
					<div class="row">
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/FQF-and-Extensions" onclick="window.open('https:https://github.com/BY571/FQF-and-Extensions')" class="image fit thumb"><img src="images/thumbs/FQF_IQN_LL_.png" alt="" /></a>
							<h3>Fully Parameterized Quantile Function (FQF) and Extensions</h3>
							<p>Implementation of the state-of-the-art distributional RL algorithm FQF including the extensions PER, Noisy Layer, Dueling Networks, and Munchausen RL. Supporting parallel environments for faster training (wall clock time). </p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/Soft-Actor-Critic-and-Extensions" onclick="window.open('https://github.com/BY571/Soft-Actor-Critic-and-Extensions')" class="image fit thumb"><img src="images/thumbs/SAC.png" alt="" /></a>
							<h3>Soft Actor Critic and Extensions</h3>
							<p>Implementation of the state-of-the-art algorithm Soft Actor Critic including extensions like PER and ERE. </p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/DQN-Atari-Agents" onclick="window.open('https://github.com/BY571/DQN-Atari-Agents')" class="image fit thumb"><img src="images/thumbs/DQN.png" alt="" /></a>
							<h3>DQN Atari Agents</h3>
							<p>Modularized implementation of the DQN algorithm and all extensions up to Rainbow DQN.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/Upside-Down-Reinforcement-Learning" onclick="window.open('https://github.com/BY571/Upside-Down-Reinforcement-Learning')" class="image fit thumb"><img src="images/thumbs/UDRL.png" alt="" /></a>
							<h3>Upside-Down-Reinforcement-Learning</h3>
							<p>Paper implementation of the algorithm Reinforcement Learning Upside Down by JÃ¼rgen Schmidhuber.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/Deep-Reinforcement-Learning-Algorithm-Collection" onclick="window.open('https://github.com/BY571/Deep-Reinforcement-Learning-Algorithm-Collection')" class="image fit thumb"><img src="images/thumbs/placeholder.png" alt="" /></a>
							<h3>Deep-Reinforcement-Learning-Algorithm-Collection</h3>
							<p>Collection of implemented DRL algorithm, including PPO, PPO2, A2C, DDPG, TD3, curiosity driven exploration etc.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/Udacity-DRL-Nanodegree-P3-Multiagent-RL-" onclick="window.open('https://github.com/BY571/Udacity-DRL-Nanodegree-P3-Multiagent-RL-')" class="image fit thumb"><img src="images/thumbs/MARL.png" alt="" /></a>
							<h3>Multi Agent RL </h3>
							<p>Train two agents playing tennis against each other.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://github.com/BY571/Autonomous-Robocar" onclick="window.open('https://github.com/BY571/Autonomous-Robocar')" class="image fit thumb"><img src="images/thumbs/car.png" alt="" /></a>
							<h3>Autonomous-Robocar</h3>
							<p>Building and training an autonomous robocar driving along a test track.</p>
						</article>
					</div>
					<ul class="actions">
						<li><a href="https://github.com/BY571" class="button">All Projects</a></li>
					</ul>
				</section>

				<section id="three">
					<h2>Article</h2>
					<div class="row">
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/distributional-reinforcement-learning-part-2-iqn-and-fqf-567fbc7a04d7" class="image fit thumb"><img src="images/thumbs/distributional_rl.png" alt="" /></a>
							<h3>Distributional Reinforcement Learning â€” Part 2 (IQN and FQF)</h3>
							<p></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/naf-normalized-advantage-function-dqn-for-continuous-control-tasks-b9dcb6ebeab8" class="image fit thumb"><img src="images/thumbs/NAF.png" alt="" /></a>
							<h3>NAF: Normalized Advantage Function â€” DQN for Continuous Control Tasks</h3>
							<p></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/advanced-exploration-hindsight-experience-replay-fd604be0fc4a" class="image fit thumb"><img src="images/thumbs/HER.png" alt="" /></a>
							<h3>Advanced Exploration: Hindsight Experience Replay</h3>
							<p></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/@sebastian.dittert3692/research-project-reinforcement-learning-upside-down-295e63d6be68" class="image fit thumb"><img src="images/thumbs/UDRL_p1.png" alt="" /></a>
							<h3>Research Project Upside Down Reinforcement Learning</h3>
							<p></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/reinforcement-learning-and-the-markov-decision-process-f0a8e65f2b0f" class="image fit thumb"><img src="images/thumbs/MRP_1.png" alt="" /></a>
							<h3>Reinforcement Learning and the Markov Decision Process</h3>
							<p>Explanation to the Markov Decision Process</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/monte-carlo-methods-in-reinforcement-learning-part-1-on-policy-methods-1f004d59686a" class="image fit thumb"><img src="images/thumbs/MC_1.png" alt="" /></a>
							<h3>Monte Carlo Methods - Part 1</h3>
							<p>Introduction to Monte Carlo Methods for Reinforcement Learning.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/reinforcement-learning-temporal-difference-learning-part-1-339fef103850" class="image fit thumb"><img src="images/thumbs/TD_1.png" alt="" /></a>
							<h3>Temporal Difference Learning - Part 1</h3>
							<p>Explanation of Temporal Difference Learning in Reinforcement Learning.</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://medium.com/analytics-vidhya/reinforcement-learning-value-function-and-policy-c22f5bd1d1b0" class="image fit thumb"><img src="images/thumbs/Pc_1.png" alt="" /></a>
							<h3>Policy and Value Function</h3>
							<p>Brief Introduction to Policies and Value Functions in Reinforcement Learning.</p>
						</article>
					</div>
					<ul class="actions">
						<li><a href="https://medium.com/@sebastian.dittert3692" class="button">All Articles</a></li>
					</ul>
				</section>
				-->

			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://www.linkedin.com/in/sebastian-dittert/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/BY571" class="icon brands fa-github"><span class="label">Github</span></a></li>	
						<li><a href="mailto:sebastian.dittert@gmx.de" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
